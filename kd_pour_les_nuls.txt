(1) Installation :

Il faut installer (via pip) ces librairies dans ton environnement:
- torch (normalement tu as déjà)
- glob → pip3 install glob2
- re → pip3 install regex
- numpy
- open-cv
- os

Installer ce repo git : https://github.com/ultralytics/yolov5 :

git clone https://github.com/ultralytics/yolov5  # clone
cd yolov5
pip install -r requirements.txt  # install
Il faut aussi prendre mes scripts en dézippant le dossier que je t’ai envoyé. Il contient 4 scripts : 
dataset.py
divers.py
generateDataset.py
generatePseudoLabels.py
Ce sont ces deux derniers que tu pourras appeler. 

(2) Générer l’arbe de donnée
Pour cela, tu dois appeler le scipt generateDataset.py en lui donnant le chemin de la vidéo que veux utiliser et le chemin du dossier parent pour la sortie :
python3 generateDataset.py --vp /path/to/video.avi --out /path/S01_c001
Si le dossier de sortie n’existe pas, il sera créé. Tu peux appeler le script avec la commande  --help pour plus d’infos.

(3) Générer les pseudos labels :
Pour cela tu dois appeler le script generatePseudoLabels.py en lui donnant le chemin du dossier parent que tu viens de créer :
python3 generatePseudoLabels.py --p /path/S01_c001
Tu peux appeler le script avec la commande  --help pour plus d’infos.

(4) Entrainer un modèle :
D’abord tu dois creer un fichier de configuration .yaml en allant dans /yolov5/data. Là tu créer un fichier que tu nommes comme ton dossier d’images (pour + de lisibilité) du genre S01_c001.yaml. Dedans tu copies-colles le texte suivant :  








# YOLOv5 🚀 by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# ├── yolov5
# └── datasets
#     └── coco128  ← downloads here (7 MB)


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../generated_dataset/S01_c001  # dataset root dir
train: train_split  # train images (relative to 'path') 128 images
val: val_split  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
nc: 80  # number of classes
names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
        'hair drier', 'toothbrush']  # class names 

Tout ce que tu as à modifier c’est le path du dossier parent.

Pour lancer l’entraînement tu dois appeler le script train.py qui se situe dans le dossier du git /yolov5. Tu dois donner le bon fichier .yaml pour le parametre --data:

python3 train.py --img 640 --batch 64 --epochs 100 --data S01_c001.yaml --weights yolov5n.pt

Et voilà ! Les poids du student entraîner sont dans /yolov5/runs/train/exp/weights/best.pt



